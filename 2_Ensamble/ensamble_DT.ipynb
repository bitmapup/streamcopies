{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiclass import ECOC\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_feature_names=[ \n",
    "                \"amount_usd\",        #-- 0 *\n",
    "                \"client_age\",        #-- 1 *\n",
    "                \"client_gender\",     #-- 2\n",
    "                \"debit_type\",        #-- 3 Credit or debit card\n",
    "                \"agency_region\",     #-- 4\n",
    "                \"merchant_departement\" #-- 5\n",
    "              ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPrediction (cum_prediction_arr):\n",
    "    \"\"\"This method makes a weighted prediction usin a set of decision trees.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cum_prediction_arr : np.array,  conatining the probability of an element belonging to a class (shape: sample,nb_classes)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    max_predictions: ndarray, containing the predicted class (throught vote) class\n",
    "    \"\"\"\n",
    "    max_predictions = []\n",
    "    for row in cum_prediction_arr:\n",
    "        max_predictions.append((np.argmax(row))+1)\n",
    "        \n",
    "    return max_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEnsamblePrediction (ensambleModels, X_test, num_clases):\n",
    "    \"\"\"This method makes a weighted prediction usin a set of decision trees.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ensambleModels : list, set of decision trees\n",
    "    X_test : ndarray, feature matrix\n",
    "    num_clases : number of classes to be predicted\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    cum_prediction_arr: ndarray, weighted prediction matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    i = 1\n",
    "\n",
    "    cum_prediction_arr = np.zeros((len(X_test), num_clases)).copy()\n",
    "    for model in ensambleModels:\n",
    "        prediction_arr = (model.estimator.predict_proba(X_test)).copy()\n",
    "        cum_prediction_arr = cum_prediction_arr.copy().__add__(prediction_arr.copy())\n",
    "        #r = export_text(model.estimator, feature_names=dataset_feature_names)\n",
    "        i +=1\n",
    "        #print (\"model {}\".format(i))\n",
    "        #print (r)\n",
    "            \n",
    "    return cum_prediction_arr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numLine acc mean_acc train_time test_time total_time memory_model (bytes)\n",
      "20000 0.7201720172017202 0.7201720172017202 0.11984705924987793 0.0026886463165283203 0.12253570556640625 96\n",
      "30000 0.6637663766376638 0.6919691969196919 0.11939382553100586 0.0037407875061035156 0.12313461303710938 96\n",
      "40000 0.8511851185118512 0.7715771577157715 0.0979311466217041 0.005682945251464844 0.10361409187316895 96\n",
      "50000 0.7886788678867886 0.7801280128012801 0.11021065711975098 0.006439924240112305 0.11665058135986328 128\n",
      "60000 0.8161816181618162 0.7981548154815481 0.11646580696105957 0.009161233901977539 0.1256270408630371 128\n",
      "70000 0.7999799979998 0.799067406740674 0.11784482002258301 0.014043807983398438 0.13188862800598145 128\n",
      "80000 0.8324832483248324 0.8157753275327533 0.1190497875213623 0.01172494888305664 0.13077473640441895 128\n",
      "90000 0.8093809380938094 0.8125781328132813 0.11916279792785645 0.013423919677734375 0.13258671760559082 192\n",
      "100000 0.8098809880988099 0.8112295604560456 0.11017704010009766 0.014962911605834961 0.12513995170593262 192\n",
      "110000 0.8026802680268027 0.8069549142414241 0.1109771728515625 0.018246889114379883 0.12922406196594238 192\n",
      "120000 0.8131813181318132 0.8100681161866186 0.12262487411499023 0.019823074340820312 0.14244794845581055 192\n",
      "130000 0.8070807080708071 0.8085744121287128 0.12325501441955566 0.02094411849975586 0.14419913291931152 192\n",
      "140000 0.8157815781578158 0.8121779951432644 0.11482000350952148 0.022565841674804688 0.13738584518432617 192\n",
      "150000 0.8286828682868287 0.8204304317150466 0.11989688873291016 0.02303314208984375 0.1429300308227539 192\n",
      "160000 0.8444844484448445 0.8324574400799456 0.11766672134399414 0.025468111038208008 0.14313483238220215 192\n",
      "170000 0.8454845484548454 0.8389709942673955 0.1170039176940918 0.025951147079467773 0.14295506477355957 264\n",
      "180000 0.84998499849985 0.8444779963836228 0.11171603202819824 0.02858114242553711 0.14029717445373535 264\n",
      "190000 0.8381838183818382 0.8413309073827304 0.12285995483398438 0.030613183975219727 0.1534731388092041 264\n",
      "200000 0.83008300830083 0.8357069578417802 0.1253221035003662 0.031805992126464844 0.15712809562683105 264\n",
      "210000 0.8154815481548154 0.8255942529982978 0.1271069049835205 0.03421592712402344 0.16132283210754395 264\n",
      "220000 0.8271827182718272 0.8263884856350625 0.12453913688659668 0.04535722732543945 0.16989636421203613 264\n",
      "230000 0.833983398339834 0.8301859419874482 0.13279008865356445 0.04053306579589844 0.1733231544494629 264\n",
      "240000 0.8317831783178318 0.83098456015264 0.14090299606323242 0.04226493835449219 0.1831679344177246 264\n",
      "250000 0.8351835183518351 0.8330840392522376 0.11931085586547852 0.045523881912231445 0.16483473777770996 264\n",
      "260000 0.9304930493049305 0.881788544278584 0.10488200187683105 0.04604697227478027 0.15092897415161133 344\n",
      "270000 0.8717871787178718 0.8767878614982278 0.11151003837585449 0.046053171157836914 0.1575632095336914 344\n",
      "280000 0.8556855685568557 0.8662367150275418 0.13266873359680176 0.051390886306762695 0.18405961990356445 344\n",
      "290000 0.85998599859986 0.863111356813701 0.1218569278717041 0.05650520324707031 0.17836213111877441 344\n",
      "300000 0.8596859685968596 0.8613986627052803 0.12531304359436035 0.05831503868103027 0.18362808227539062 344\n",
      "310000 0.8650865086508651 0.8632425856780728 0.13282299041748047 0.06305670738220215 0.19587969779968262 344\n",
      "320000 0.8440844084408441 0.8536634970594584 0.13873720169067383 0.06147885322570801 0.20021605491638184 344\n",
      "330000 0.8368836883688369 0.8452735927141477 0.1393740177154541 0.0640418529510498 0.2034158706665039 344\n",
      "340000 0.8344834483448345 0.8398785205294911 0.13634371757507324 0.07038402557373047 0.2067277431488037 344\n",
      "350000 0.8371837183718371 0.8385311194506642 0.14298486709594727 0.0688629150390625 0.21184778213500977 344\n",
      "360000 0.8312831283128312 0.8349071238817477 0.1405041217803955 0.0737302303314209 0.2142343521118164 432\n",
      "370000 0.8455845584558456 0.8402458411687966 0.1320631504058838 0.07347989082336426 0.20554304122924805 432\n",
      "380000 0.8583858385838584 0.8493158398763275 0.12212491035461426 0.0742340087890625 0.19635891914367676 432\n",
      "390000 0.8830883088308831 0.8662020743536053 0.11528873443603516 0.07479405403137207 0.19008278846740723 432\n",
      "400000 0.8805880588058805 0.873395066579743 0.12248921394348145 0.07684183120727539 0.19933104515075684 432\n",
      "410000 0.8752875287528753 0.8743412976663092 0.12035083770751953 0.07521986961364746 0.195570707321167 432\n",
      "420000 0.8624862486248625 0.8684137731455859 0.11827397346496582 0.07864809036254883 0.19692206382751465 432\n",
      "430000 0.8560856085608561 0.862249690853221 0.13336777687072754 0.08237099647521973 0.21573877334594727 432\n",
      "440000 0.8536853685368537 0.8579675296950373 0.13029098510742188 0.08079791069030762 0.2110888957977295 432\n",
      "450000 0.8556855685568557 0.8568265491259466 0.12442994117736816 0.0814371109008789 0.20586705207824707 432\n",
      "460000 0.8512851285128513 0.854055838819399 0.12238311767578125 0.08333992958068848 0.20572304725646973 432\n",
      "470000 0.8383838383838383 0.8462198386016186 0.12238001823425293 0.08737516403198242 0.20975518226623535 528\n",
      "480000 0.8333833383338334 0.839801588467726 0.1256101131439209 0.08880996704101562 0.21442008018493652 528\n",
      "490000 0.8275827582758276 0.8336921733717768 0.1293182373046875 0.0907280445098877 0.2200462818145752 528\n",
      "500000 0.8791879187918792 0.856440046081828 0.1209259033203125 0.08467888832092285 0.20560479164123535 528\n",
      "510000 0.8648864886488649 0.8606632673653465 0.12399697303771973 0.09309005737304688 0.2170870304107666 528\n",
      "520000 0.8686868686868687 0.8646750680261076 0.12091398239135742 0.09492921829223633 0.21584320068359375 528\n",
      "530000 0.8671867186718671 0.8659308933489873 0.12366175651550293 0.09743714332580566 0.2210988998413086 528\n",
      "540000 0.8526852685268527 0.85930808093792 0.12062788009643555 0.09512519836425781 0.21575307846069336 528\n",
      "550000 0.846984698469847 0.8531463897038836 0.12962102890014648 0.10179829597473145 0.23141932487487793 528\n",
      "560000 0.8381838183818382 0.8456651040428609 0.12247276306152344 0.10069012641906738 0.22316288948059082 528\n",
      "570000 0.832083208320832 0.8388741561818465 0.12310791015625 0.1069638729095459 0.2300717830657959 528\n",
      "580000 0.834983498349835 0.8369288272658407 0.13889002799987793 0.1047508716583252 0.24364089965820312 528\n",
      "590000 0.8372837283728373 0.837106277819339 0.1282799243927002 0.10872077941894531 0.2370007038116455 640\n",
      "600000 0.8507850785078508 0.8439456781635949 0.12440085411071777 0.10774707794189453 0.2321479320526123 640\n",
      "610000 0.8701870187018702 0.8570663484327325 0.12331104278564453 0.11023378372192383 0.23354482650756836 640\n",
      "620000 0.8685868586858686 0.8628266035593006 0.11964893341064453 0.10846304893493652 0.22811198234558105 640\n",
      "630000 0.8593859385938594 0.86110627107658 0.12029385566711426 0.11063385009765625 0.2309277057647705 640\n",
      "640000 0.8616861686168616 0.8613962198467209 0.11515092849731445 0.11218619346618652 0.22733712196350098 640\n",
      "650000 0.8364836483648365 0.8489399341057786 0.12183213233947754 0.11390900611877441 0.23574113845825195 640\n",
      "660000 0.8350835083508351 0.8420117212283069 0.12459015846252441 0.11884403228759766 0.24343419075012207 640\n",
      "670000 0.8377837783778378 0.8398977498030724 0.11898398399353027 0.11843991279602051 0.23742389678955078 640\n",
      "680000 0.847984798479848 0.8439412741414603 0.11872577667236328 0.1200709342956543 0.23879671096801758 640\n",
      "690000 0.8463846384638464 0.8451629563026533 0.12241697311401367 0.11972904205322266 0.24214601516723633 640\n",
      "700000 0.8763876387638764 0.8607752975332648 0.12161087989807129 0.11765813827514648 0.23926901817321777 640\n",
      "710000 0.8622862286228623 0.8615307630780635 0.11517906188964844 0.11861205101013184 0.23379111289978027 640\n",
      "720000 0.862986298629863 0.8622585308539632 0.12671685218811035 0.1248021125793457 0.25151896476745605 640\n",
      "730000 0.8611861186118612 0.8617223247329122 0.12166810035705566 0.1269981861114502 0.24866628646850586 768\n",
      "740000 0.8361836183618362 0.8489529715473743 0.12169671058654785 0.12426114082336426 0.2459578514099121 768\n",
      "750000 0.841984198419842 0.8454685849836081 0.11315608024597168 0.128554105758667 0.24171018600463867 768\n",
      "760000 0.8461846184618462 0.8458266017227272 0.11945533752441406 0.13277506828308105 0.2522304058074951 768\n",
      "770000 0.8496849684968497 0.8477557851097884 0.12158060073852539 0.13257813453674316 0.25415873527526855 768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780000 0.8572857285728572 0.8525207568413229 0.11770987510681152 0.13086295127868652 0.24857282638549805 768\n",
      "790000 0.8808880888088809 0.866704422825102 0.11143112182617188 0.13333702087402344 0.2447681427001953 768\n",
      "800000 0.8662866286628663 0.8664955257439841 0.11675906181335449 0.13260221481323242 0.24936127662658691 768\n",
      "810000 0.8691869186918691 0.8678412222179266 0.1052858829498291 0.13727903366088867 0.24256491661071777 768\n",
      "820000 0.8686868686868687 0.8682640454523977 0.1127622127532959 0.14126086235046387 0.25402307510375977 768\n",
      "830000 0.8511851185118512 0.8597245819821244 0.10712909698486328 0.1425769329071045 0.24970602989196777 768\n",
      "840000 0.8401840184018402 0.8499543001919823 0.12998390197753906 0.14424395561218262 0.2742278575897217 768\n",
      "850000 0.8438843884388438 0.846919344315413 0.11347293853759766 0.14590787887573242 0.2593808174133301 768\n",
      "860000 0.8483848384838484 0.8476520913996307 0.12595105171203613 0.14725804328918457 0.2732090950012207 768\n",
      "870000 0.8633863386338634 0.855519215016747 0.11255121231079102 0.15056943893432617 0.2631206512451172 768\n",
      "880000 0.8785878587858786 0.8670535369013128 0.11894512176513672 0.14518213272094727 0.264127254486084 768\n",
      "890000 0.8670867086708671 0.86707012278609 0.11029481887817383 0.150892972946167 0.2611877918243408 912\n",
      "900000 0.8661866186618662 0.8666283707239781 0.11252498626708984 0.15046906471252441 0.26299405097961426 912\n",
      "910000 0.8815881588158816 0.8741082647699299 0.11532902717590332 0.15610814094543457 0.2714371681213379 912\n",
      "920000 0.8516851685168517 0.8628967166433907 0.12333273887634277 0.1561117172241211 0.27944445610046387 912\n",
      "930000 0.8474847484748474 0.855190732559119 0.11839008331298828 0.15883111953735352 0.2772212028503418 912\n",
      "940000 0.838983898389839 0.847087315474479 0.12079787254333496 0.16426897048950195 0.2850668430328369 912\n",
      "950000 0.8488848884888489 0.8479861019816639 0.12319803237915039 0.1695880889892578 0.2927861213684082 912\n",
      "960000 0.849084908490849 0.8485355052362564 0.11579084396362305 0.16535186767578125 0.2811427116394043 912\n",
      "970000 0.8644864486448645 0.8565109769405604 0.11811995506286621 0.16204166412353516 0.28016161918640137 912\n",
      "980000 0.8797879787978797 0.86814947786922 0.11470198631286621 0.16539525985717773 0.28009724617004395 912\n",
      "990000 0.8735873587358736 0.8708684183025468 0.1071629524230957 0.1649458408355713 0.272108793258667 912\n"
     ]
    }
   ],
   "source": [
    "#read dataset\n",
    "ensamble=[]\n",
    "predictions=[]\n",
    "batch_size=10000\n",
    "f= open(\"summary_ensemble_dt.txt\",\"w+\")\n",
    "aux_list = []\n",
    "X_ = []\n",
    "y_ = []\n",
    "i =0 \n",
    "numLine = 0\n",
    "mean_acc = 0\n",
    "print (\"numLine\",\"acc\",\"mean_acc\", \"train_time\",\"test_time\",\"total_time\",\"memory_model (bytes)\" )\n",
    "f.write(\"id,acc,mean_acc,train_time,test_time,total_time,memory_model (bytes)\\n\")\n",
    "with open(\"../data_output/export_dataframe_0v4.csv\") as infile:\n",
    "    for line in infile:\n",
    "        # windows is not full. We add records \n",
    "        if (i < batch_size):\n",
    "            aux_list= (line.split(\",\"))\n",
    "            aux_y = int(aux_list.pop())\n",
    "            aux_x = np.array(aux_list.copy(),dtype=np.float32) \n",
    "            y_.append( aux_y )        \n",
    "            X_.append(aux_x)  \n",
    "\n",
    "        else: #windows is full\n",
    "            X = np.asarray(X_).copy()\n",
    "            y = np.asarray(y_).copy()\n",
    "            \n",
    "            #Is the first mode?\n",
    "            if (len(ensamble) == 0 ): \n",
    "                \n",
    "                start_train = time.time()\n",
    "                parameters = {'max_depth':[None]}\n",
    "                clf = GridSearchCV(tree.DecisionTreeClassifier(class_weight='balanced'), parameters, n_jobs=-1)\n",
    "                clf.fit(X, y)\n",
    "                tree_model = clf.best_estimator_\n",
    "                end_train = time.time()\n",
    "                train_time = end_train - start_train\n",
    "                \n",
    "                ensamble.append( ECOC(tree_model) )\n",
    "                ensamble[-1].estimator.classes_ = [1,2]\n",
    "                ensamble[-1].estimator.n_classes_= 2\n",
    "                memory_model = sys.getsizeof(ensamble)\n",
    "            else:# It is not the first model\n",
    "                start_test = time.time()\n",
    "                pred_arr = (makeEnsamblePrediction(ensamble,X.copy(),2)).copy()\n",
    "                end_test = time.time()\n",
    "                test_time = end_test - start_test\n",
    "                \n",
    "                start_train = time.time()\n",
    "                parameters = {'max_depth':[None]}\n",
    "                clf = GridSearchCV(tree.DecisionTreeClassifier(class_weight='balanced'), parameters, n_jobs=-1)\n",
    "                clf.fit(X, y)\n",
    "                tree_model = clf.best_estimator_\n",
    "                \n",
    "                end_train = time.time()\n",
    "                train_time = end_train - start_train\n",
    "                \n",
    "                ensamble.append( ECOC(tree_model) )\n",
    "                ensamble[-1].estimator.classes_ = [1,2]\n",
    "                ensamble[-1].estimator.n_classes_= 2\n",
    "                memory_model = sys.getsizeof(ensamble)\n",
    "                predictions.append(pred_arr)\n",
    "                y_pred = extractPrediction(predictions[-1])\n",
    "                acc = accuracy_score(y, y_pred)\n",
    "                \n",
    "                #compute mean accuracy\n",
    "                if mean_acc == 0 :\n",
    "                    mean_acc = acc\n",
    "                else:\n",
    "                    mean_acc = (acc + mean_acc)/2\n",
    "                  \n",
    "                print (numLine,acc,mean_acc, train_time,test_time,(train_time+test_time),memory_model)\n",
    "                f.write(\"{},{},{},{},{},{},{}\\n\".format(numLine,acc,mean_acc, train_time,\n",
    "                                  test_time,(train_time+test_time),memory_model))\n",
    "            \n",
    "            X_=[]\n",
    "            y_=[]            \n",
    "            i=0\n",
    "            \n",
    "        i+=1\n",
    "        numLine += 1\n",
    "f.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlineHT",
   "language": "python",
   "name": "onlineht"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
