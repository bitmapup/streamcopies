{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiclass import ECOC\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_feature_names=[ \n",
    "                \"amount_usd\",        #-- 0 *\n",
    "                \"client_age\",        #-- 1 *\n",
    "                \"client_gender\",     #-- 2\n",
    "                \"debit_type\",        #-- 3 Credit or debit card\n",
    "                \"agency_region\",     #-- 4\n",
    "                \"merchant_departement\" #-- 5\n",
    "              ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPrediction (cum_prediction_arr):\n",
    "    \"\"\"This method makes a weighted prediction usin a set of decision trees.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cum_prediction_arr : np.array,  conatining the probability of an element belonging to a class (shape: sample,nb_classes)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    max_predictions: ndarray, containing the predicted class (throught vote) class\n",
    "    \"\"\"\n",
    "    max_predictions = []\n",
    "    for row in cum_prediction_arr:\n",
    "        max_predictions.append((np.argmax(row))+1)\n",
    "        \n",
    "    return max_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEnsamblePrediction (ensambleModels, X_test, num_clases):\n",
    "    \"\"\"This method makes a weighted prediction usin a set of decision trees.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ensambleModels : list, set of decision trees\n",
    "    X_test : ndarray, feature matrix\n",
    "    num_clases : number of classes to be predicted\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    cum_prediction_arr: ndarray, weighted prediction matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    i = 1\n",
    "\n",
    "    cum_prediction_arr = np.zeros((len(X_test), num_clases)).copy()\n",
    "    for model in ensambleModels:\n",
    "        prediction_arr = (model.estimator.predict_proba(X_test)).copy()\n",
    "        cum_prediction_arr = cum_prediction_arr.copy().__add__(prediction_arr.copy())\n",
    "        #r = export_text(model.estimator, feature_names=dataset_feature_names)\n",
    "        i +=1\n",
    "        #print (\"model {}\".format(i))\n",
    "        #print (r)\n",
    "            \n",
    "    return cum_prediction_arr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numLine acc mean_acc train_time test_time total_time memory_model (bytes)\n",
      "20000 0.0593059305930593 0.0593059305930593 0.3530611991882324 0.003069162368774414 0.35613036155700684 96\n",
      "30000 0.09160916091609161 0.07545754575457546 0.3253049850463867 0.003612041473388672 0.3289170265197754 96\n",
      "40000 0.0428042804280428 0.059130913091309134 0.1171419620513916 0.0049779415130615234 0.12211990356445312 96\n",
      "50000 0.052805280528052806 0.05596809680968097 0.12107014656066895 0.006803989410400391 0.12787413597106934 128\n",
      "60000 0.0406040604060406 0.048286078607860786 0.12015008926391602 0.008685111999511719 0.12883520126342773 128\n",
      "70000 0.050505050505050504 0.04939556455645565 0.127061128616333 0.009621143341064453 0.13668227195739746 128\n",
      "80000 0.034403440344034406 0.04189950245024503 0.11926007270812988 0.011661052703857422 0.1309211254119873 128\n",
      "90000 0.04590459045904591 0.04390204645464547 0.12499308586120605 0.012517929077148438 0.1375110149383545 192\n",
      "100000 0.0332033203320332 0.03855268339333934 0.11185407638549805 0.013736248016357422 0.12559032440185547 192\n",
      "110000 0.039003900390039 0.03877829189168917 0.12335896492004395 0.015115022659301758 0.1384739875793457 192\n",
      "120000 0.0391039103910391 0.038941101141364134 0.11953020095825195 0.01742696762084961 0.13695716857910156 192\n",
      "130000 0.039603960396039604 0.039272530768701866 0.11475896835327148 0.018458127975463867 0.13321709632873535 192\n",
      "140000 0.0337033703370337 0.036487950552867784 0.11723875999450684 0.020420312881469727 0.13765907287597656 192\n",
      "150000 0.041304130413041304 0.038896040482954544 0.11444687843322754 0.02205681800842285 0.1365036964416504 192\n",
      "160000 0.0335033503350335 0.03619969540899402 0.11119294166564941 0.023225069046020508 0.13441801071166992 192\n",
      "170000 0.038003800380038005 0.037101747894516014 0.11846280097961426 0.023776769638061523 0.14223957061767578 264\n",
      "180000 0.032303230323032305 0.03470248910877416 0.13135695457458496 0.02540898323059082 0.15676593780517578 264\n",
      "190000 0.039003900390039 0.036853194749406584 0.1172189712524414 0.027390003204345703 0.1446089744567871 264\n",
      "200000 0.033903390339033904 0.035378292544220244 0.12965011596679688 0.028975725173950195 0.15862584114074707 264\n",
      "210000 0.0331033103310331 0.03424080143762667 0.12125968933105469 0.03224492073059082 0.1535046100616455 264\n",
      "220000 0.035003500350035 0.03462215089383083 0.13042688369750977 0.0339047908782959 0.16433167457580566 264\n",
      "230000 0.036003600360036005 0.035312875626933415 0.11280298233032227 0.036356210708618164 0.14915919303894043 264\n",
      "240000 0.034303430343034305 0.03480815298498386 0.13078093528747559 0.03700613975524902 0.1677870750427246 264\n",
      "250000 0.0332033203320332 0.034005736658508534 0.13819503784179688 0.03836989402770996 0.17656493186950684 264\n",
      "260000 0.0315031503150315 0.03275444348677002 0.10297894477844238 0.03882098197937012 0.1417999267578125 344\n",
      "270000 0.038103810381038106 0.035429126933904063 0.11941313743591309 0.04005694389343262 0.1594700813293457 344\n",
      "280000 0.033903390339033904 0.03466625863646898 0.1204078197479248 0.04018831253051758 0.16059613227844238 344\n",
      "290000 0.0336033603360336 0.03413480948625129 0.12791180610656738 0.043489933013916016 0.1714017391204834 344\n",
      "300000 0.036303630363036306 0.0352192199246438 0.1127171516418457 0.044587135314941406 0.1573042869567871 344\n",
      "310000 0.0348034803480348 0.0350113501363393 0.12424206733703613 0.0467531681060791 0.17099523544311523 344\n",
      "320000 0.030803080308030802 0.03290721522218505 0.11896300315856934 0.04766201972961426 0.1666250228881836 344\n",
      "330000 0.0338033803380338 0.03335529778010943 0.11860990524291992 0.04781699180603027 0.1664268970489502 344\n",
      "340000 0.0348034803480348 0.03407938906407211 0.12326717376708984 0.05093193054199219 0.17419910430908203 344\n",
      "350000 0.0349034903490349 0.03449143970655351 0.11475729942321777 0.05387377738952637 0.16863107681274414 344\n",
      "360000 0.0334033403340334 0.033947390020293455 0.11690521240234375 0.05525779724121094 0.1721630096435547 432\n",
      "370000 0.0368036803680368 0.03537553519416513 0.11783981323242188 0.05586504936218262 0.1737048625946045 432\n",
      "380000 0.034103410341034104 0.034739472767599616 0.12358283996582031 0.05983400344848633 0.18341684341430664 432\n",
      "390000 0.0349034903490349 0.034821481558317255 0.11827874183654785 0.06141209602355957 0.17969083786010742 432\n",
      "400000 0.0331033103310331 0.03396239594467518 0.11753320693969727 0.06356501579284668 0.18109822273254395 432\n",
      "410000 0.0336033603360336 0.03378287814035439 0.12012791633605957 0.06393289566040039 0.18406081199645996 432\n",
      "420000 0.0334033403340334 0.0335931092371939 0.11320996284484863 0.06357502937316895 0.17678499221801758 432\n",
      "430000 0.0336033603360336 0.03359823478661375 0.11662817001342773 0.0668332576751709 0.18346142768859863 432\n",
      "440000 0.032703270327032706 0.03315075255682323 0.11807823181152344 0.06739687919616699 0.18547511100769043 432\n",
      "450000 0.033003300330033 0.033077026443428116 0.12885403633117676 0.06612396240234375 0.1949779987335205 432\n",
      "460000 0.034003400340034004 0.033540213391731064 0.10815811157226562 0.06968498229980469 0.1778430938720703 432\n",
      "470000 0.033003300330033 0.03327175686088203 0.11613202095031738 0.07202506065368652 0.1881570816040039 528\n",
      "480000 0.036003600360036005 0.03463767861045902 0.11742186546325684 0.07254505157470703 0.18996691703796387 528\n",
      "490000 0.038103810381038106 0.036370744495748564 0.12195897102355957 0.0735161304473877 0.19547510147094727 528\n",
      "500000 0.033903390339033904 0.035137067417391234 0.14884614944458008 0.07871580123901367 0.22756195068359375 528\n",
      "510000 0.034203420342034205 0.03467024387971272 0.13463211059570312 0.08422183990478516 0.21885395050048828 528\n",
      "520000 0.032503250325032505 0.03358674710237261 0.1201019287109375 0.07893013954162598 0.19903206825256348 528\n",
      "530000 0.0336033603360336 0.033595053719203107 0.1237940788269043 0.08080792427062988 0.20460200309753418 528\n",
      "540000 0.0334033403340334 0.03349919702661826 0.1308608055114746 0.08599519729614258 0.2168560028076172 528\n",
      "550000 0.0332033203320332 0.03335125867932573 0.13402414321899414 0.08483028411865234 0.21885442733764648 528\n",
      "560000 0.034103410341034104 0.03372733451017992 0.13495397567749023 0.08371400833129883 0.21866798400878906 528\n",
      "570000 0.033903390339033904 0.03381536242460691 0.12385296821594238 0.0865333080291748 0.2103862762451172 528\n",
      "580000 0.0334033403340334 0.033609351379320154 0.13910984992980957 0.08916926383972168 0.22827911376953125 528\n",
      "590000 0.0353035303530353 0.03445644086617773 0.12659406661987305 0.08705687522888184 0.21365094184875488 640\n",
      "600000 0.0338033803380338 0.03412991060210577 0.126295804977417 0.091522216796875 0.217818021774292 640\n",
      "610000 0.034103410341034104 0.034116660471569936 0.12758278846740723 0.09166908264160156 0.2192518711090088 640\n",
      "620000 0.032303230323032305 0.03320994539730112 0.14813590049743652 0.09591984748840332 0.24405574798583984 640\n",
      "630000 0.034303430343034305 0.03375668787016771 0.11862301826477051 0.09525203704833984 0.21387505531311035 640\n",
      "640000 0.03470347034703471 0.03423007910860121 0.12375235557556152 0.09740495681762695 0.22115731239318848 640\n",
      "650000 0.034303430343034305 0.03426675472581776 0.12068915367126465 0.10168695449829102 0.22237610816955566 640\n",
      "660000 0.0329032903290329 0.03358502252742533 0.12356090545654297 0.10026717185974121 0.22382807731628418 640\n",
      "670000 0.035903590359035904 0.03474430644323062 0.12078595161437988 0.10587286949157715 0.22665882110595703 640\n",
      "680000 0.0338033803380338 0.03427384339063221 0.11318397521972656 0.10707521438598633 0.2202591896057129 640\n",
      "690000 0.034103410341034104 0.034188626865833155 0.11717700958251953 0.11245989799499512 0.22963690757751465 640\n",
      "700000 0.0313031303130313 0.03274587858943223 0.1290450096130371 0.11010503768920898 0.2391500473022461 640\n",
      "710000 0.03470347034703471 0.03372467446823347 0.13243603706359863 0.11324000358581543 0.24567604064941406 640\n",
      "720000 0.0314031403140314 0.032563907391132435 0.11823201179504395 0.11712002754211426 0.2353520393371582 640\n",
      "730000 0.0337033703370337 0.03313363886408307 0.12129688262939453 0.11646103858947754 0.23775792121887207 768\n",
      "740000 0.034203420342034205 0.03366852960305863 0.1295630931854248 0.11630487442016602 0.24586796760559082 768\n",
      "750000 0.0331033103310331 0.03338591996704587 0.12797307968139648 0.12052297592163086 0.24849605560302734 768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760000 0.033003300330033 0.03319461014853943 0.11405706405639648 0.12659597396850586 0.24065303802490234 768\n",
      "770000 0.0337033703370337 0.033448990242786567 0.1330118179321289 0.12252378463745117 0.2555356025695801 768\n",
      "780000 0.0372037203720372 0.035326355307411884 0.1322019100189209 0.13034510612487793 0.26254701614379883 768\n",
      "790000 0.034103410341034104 0.034714882824223 0.13257408142089844 0.12285900115966797 0.2554330825805664 768\n",
      "800000 0.029402940294029404 0.0320589115591262 0.12517189979553223 0.1272900104522705 0.25246191024780273 768\n",
      "810000 0.0372037203720372 0.0346313159655817 0.13176393508911133 0.132551908493042 0.2643158435821533 768\n",
      "820000 0.032503250325032505 0.0335672831453071 0.11654210090637207 0.13544583320617676 0.25198793411254883 768\n",
      "830000 0.0368036803680368 0.03518548175667195 0.1412949562072754 0.13341093063354492 0.2747058868408203 768\n",
      "840000 0.0331033103310331 0.034144396043852526 0.125870943069458 0.13610100746154785 0.26197195053100586 768\n",
      "850000 0.0337033703370337 0.033923883190443115 0.12392401695251465 0.14405202865600586 0.2679760456085205 768\n",
      "860000 0.033903390339033904 0.033913636764738506 0.12763285636901855 0.14000320434570312 0.2676360607147217 768\n",
      "870000 0.032303230323032305 0.0331084335438854 0.12476515769958496 0.13551092147827148 0.26027607917785645 768\n",
      "880000 0.0333033303330333 0.03320588193845935 0.12205719947814941 0.13965678215026855 0.26171398162841797 768\n",
      "890000 0.0337033703370337 0.033454626137746524 0.13305377960205078 0.14136004447937012 0.2744138240814209 912\n",
      "900000 0.0319031903190319 0.03267890822838922 0.12836885452270508 0.14768218994140625 0.27605104446411133 912\n",
      "910000 0.03840384038403841 0.03554137430621381 0.12772083282470703 0.14987897872924805 0.2775998115539551 912\n",
      "920000 0.0369036903690369 0.03622253233762536 0.1399390697479248 0.14450788497924805 0.28444695472717285 912\n",
      "930000 0.034003400340034004 0.03511296633882968 0.12236905097961426 0.1488962173461914 0.27126526832580566 912\n",
      "940000 0.029402940294029404 0.03225795331642954 0.12481904029846191 0.14899611473083496 0.2738151550292969 912\n",
      "950000 0.0336033603360336 0.03293065682623157 0.1329052448272705 0.15467596054077148 0.287581205368042 912\n",
      "960000 0.028602860286028604 0.030766758556130088 0.11928200721740723 0.15408110618591309 0.2733631134033203 912\n",
      "970000 0.0329032903290329 0.031835024442581496 0.12263274192810059 0.15603303909301758 0.27866578102111816 912\n",
      "980000 0.031203120312031204 0.03151907237730635 0.12277698516845703 0.15581274032592773 0.27858972549438477 912\n",
      "990000 0.032803280328032806 0.032161176352669574 0.1239328384399414 0.16280817985534668 0.2867410182952881 912\n"
     ]
    }
   ],
   "source": [
    "#read dataset\n",
    "ensamble=[]\n",
    "predictions=[]\n",
    "batch_size=10000\n",
    "f= open(\"summary_ensemble_dt.txt\",\"w+\")\n",
    "aux_list = []\n",
    "X_ = []\n",
    "y_ = []\n",
    "i =0 \n",
    "numLine = 0\n",
    "mean_acc = 0\n",
    "print (\"numLine\",\"acc\",\"mean_acc\", \"train_time\",\"test_time\",\"total_time\",\"memory_model (bytes)\" )\n",
    "f.write(\"id,acc,mean_acc,train_time,test_time,total_time,memory_model (bytes)\\n\")\n",
    "#with open(\"../data_output/export_dataframe_0v4.csv\") as infile:\n",
    "\n",
    "with open(\"../data_output/balanced.csv\") as infile:\n",
    "    for line in infile:\n",
    "        # windows is not full. We add records \n",
    "        if (i < batch_size):\n",
    "            aux_list= (line.split(\",\"))\n",
    "            aux_y = int(aux_list.pop())\n",
    "            aux_x = np.array(aux_list.copy(),dtype=np.float32) \n",
    "            y_.append( aux_y )        \n",
    "            X_.append(aux_x)  \n",
    "\n",
    "        else: #windows is full\n",
    "            X = np.asarray(X_).copy()\n",
    "            y = np.asarray(y_).copy()\n",
    "            \n",
    "            #Is the first mode?\n",
    "            if (len(ensamble) == 0 ): \n",
    "                \n",
    "                start_train = time.time()\n",
    "                parameters = {'max_depth':[None]}\n",
    "                clf = GridSearchCV(tree.DecisionTreeClassifier(class_weight='balanced'), parameters, n_jobs=-1)\n",
    "                clf.fit(X, y)\n",
    "                tree_model = clf.best_estimator_\n",
    "                end_train = time.time()\n",
    "                train_time = end_train - start_train\n",
    "                \n",
    "                ensamble.append( ECOC(tree_model) )\n",
    "                ensamble[-1].estimator.classes_ = [1,2]\n",
    "                ensamble[-1].estimator.n_classes_= 2\n",
    "                memory_model = sys.getsizeof(ensamble)\n",
    "            else:# It is not the first model\n",
    "                start_test = time.time()\n",
    "                pred_arr = (makeEnsamblePrediction(ensamble,X.copy(),2)).copy()\n",
    "                end_test = time.time()\n",
    "                test_time = end_test - start_test\n",
    "                \n",
    "                start_train = time.time()\n",
    "                parameters = {'max_depth':[None]}\n",
    "                clf = GridSearchCV(tree.DecisionTreeClassifier(class_weight='balanced'), parameters, n_jobs=-1)\n",
    "                clf.fit(X, y)\n",
    "                tree_model = clf.best_estimator_\n",
    "                \n",
    "                end_train = time.time()\n",
    "                train_time = end_train - start_train\n",
    "                \n",
    "                ensamble.append( ECOC(tree_model) )\n",
    "                ensamble[-1].estimator.classes_ = [1,2]\n",
    "                ensamble[-1].estimator.n_classes_= 2\n",
    "                memory_model = sys.getsizeof(ensamble)\n",
    "                predictions.append(pred_arr)\n",
    "                y_pred = extractPrediction(predictions[-1])\n",
    "                acc = accuracy_score(y, y_pred)\n",
    "                \n",
    "                #compute mean accuracy\n",
    "                if mean_acc == 0 :\n",
    "                    mean_acc = acc\n",
    "                else:\n",
    "                    mean_acc = (acc + mean_acc)/2\n",
    "                  \n",
    "                print (numLine,acc,mean_acc, train_time,test_time,(train_time+test_time),memory_model)\n",
    "                f.write(\"{},{},{},{},{},{},{}\\n\".format(numLine,acc,mean_acc, train_time,\n",
    "                                  test_time,(train_time+test_time),memory_model))\n",
    "            \n",
    "            X_=[]\n",
    "            y_=[]            \n",
    "            i=0\n",
    "            \n",
    "        i+=1\n",
    "        numLine += 1\n",
    "f.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlineHT",
   "language": "python",
   "name": "onlineht"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
