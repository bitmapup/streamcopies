{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import sys\n",
    "import pprint\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#sys.path.append(\"../Mfig/\")\n",
    "#import mplp\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "from scipy.stats import entropy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conectionDB():\n",
    "    conn_string = \"dbname='stic' port='5432' user='stic' password='stic2019' host='gpmaster.as-dell.copernic.local'\"\n",
    "    #print (\"Connecting to database ->{}\".format(conn_string))\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dpto = dict()\n",
    "dict_province = dict()\n",
    "dict_district = dict()\n",
    "with open('../data/ubigeo_inei.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        #print (row)\n",
    "        if (str(row[0])!=''):\n",
    "            dict_dpto[str(row[3]).lower()]=(str(row[0]))\n",
    "        if (str(row[1])!=''):\n",
    "            dict_province[(row[4]).lower()]=(row[0]+''+row[1])\n",
    "        if (str(row[2])!=''):\n",
    "            dict_district[(row[5]).lower()]=(row[0]+''+row[1]+''+row[2])\n",
    "        \n",
    "dict_gender = {'M':1,'F':0,'':-1}\n",
    "dict_card = {'TD':1,'TC':0,'':-1}\n",
    "dict_region = {'NORTE':0,'ORIENTE':1,'SUR':2,'CENTRO':3,'SIERRA CENTRAL':4,\n",
    "               'LIMA CENTRO':5,'LIMA ESTE':6,'LIMA SUR':7,'LIMA NORTE':8,\n",
    "               'LIMA MODERNA':9,'LIMA PROVINCIA':10,'CALLAO':11,'':12}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames=[ \n",
    "        'social_class' ,     #-- 0\n",
    "        'country_code',      #-- 1\n",
    "        'amount_usd',        #-- 2 *\n",
    "        'client_age',        #-- 3 *\n",
    "        'client_gender',     #-- 4\n",
    "        'debit_type',        #-- 5 Credit or debit card\n",
    "        'agency_region',     #-- 9\n",
    "        'merchant_departement', #-- 10\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extraction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all (index):\n",
    "    PLIMIT = 1000000\n",
    "    POFFSET = 1000000\n",
    "    #NUM = 93 # Millions of records (92 470 071)\n",
    "    NUM = 2 #for test \n",
    "    i=index\n",
    "    while (i < NUM):\n",
    "        print (\"Processing {}/{} ...\".format(i,NUM))\n",
    "        query =\"\"\"\n",
    "            SELECT \n",
    "                social_class,      -- 0\n",
    "                amount_usd,        -- 1 *\n",
    "                client_age,        -- 2 *\n",
    "                client_gender,     -- 3\n",
    "                debit_type,        -- 4 Credit or debit card\n",
    "                agency_region,     -- 5\n",
    "                merchant_departement -- 6\n",
    "            FROM \n",
    "                public.bbva \n",
    "            INNER JOIN \n",
    "                client\n",
    "            ON \n",
    "                client.client_id = bbva.client_id\n",
    "            WHERE\n",
    "                bbva.merchant_id != '00000000'\n",
    "            ORDER BY \n",
    "                bbva.date ASC\n",
    "            LIMIT {}\n",
    "            OFFSET {}\n",
    "        ;\n",
    "        \"\"\".format(PLIMIT,POFFSET*i)\n",
    "        conn = conectionDB()\n",
    "        cursor = conn.cursor();\n",
    "        df = pd.read_sql(query, conn)\n",
    "        df.fillna(-1, inplace=True)\n",
    "        \n",
    "        df['small_social_class'] = df.apply(lambda row: 1 if (row.social_class<=3) else 0 , axis=1)\n",
    "        del df['social_class']\n",
    "      \n",
    "        df=df.replace({ \"merchant_departement\":dict_dpto,\n",
    "                        \"agency_region\": dict_region\n",
    "                         })\n",
    "        df.fillna(-1, inplace=True)\n",
    "        ###############################        \n",
    "        #  Normalize numeric columns  #\n",
    "        ###############################\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        \n",
    "        # Create x, where x the 'scores' column's values as floats\n",
    "        x_amount_usd = df[['amount_usd']].values.astype(float)\n",
    "        x_client_age = df[['client_age']].values.astype(float)\n",
    "\n",
    "        # Create an object to transform the data to fit minmax processor\n",
    "        x_scaled_amount_usd = min_max_scaler.fit_transform(x_amount_usd)\n",
    "        x_scaled_client_age = min_max_scaler.fit_transform(x_client_age)\n",
    "\n",
    "        # Run the normalizer on the dataframe\n",
    "        df_normalized_amount_usd = pd.DataFrame(x_scaled_amount_usd)\n",
    "        df_normalized_client_age = pd.DataFrame(x_scaled_client_age)\n",
    "        \n",
    "        #######################################        \n",
    "        #  One hot enconding numeric columns  #\n",
    "        #######################################\n",
    "        \n",
    "        df_client_gender_henc = pd.get_dummies(df['client_gender'], prefix = 'client_gender_')\n",
    "        df_debit_type_henc = pd.get_dummies(df['debit_type'], prefix = 'debit_type_')\n",
    "        df_agency_region_henc = pd.get_dummies(df['agency_region'], prefix = 'agency_region_')\n",
    "        df_merchant_departement_henc = pd.get_dummies(df['merchant_departement'], prefix = 'merchant_departement_')\n",
    "        \n",
    "        newdf = pd.concat([df_normalized_amount_usd, \n",
    "                   df_normalized_client_age,\n",
    "                   df_client_gender_henc,\n",
    "                   df_debit_type_henc,\n",
    "                   df_agency_region_henc,\n",
    "                   df_merchant_departement_henc\n",
    "                  ], axis=1)\n",
    "        newdf['social_class'] = df['small_social_class']\n",
    "        \n",
    "        newdf = newdf[newdf['merchant_departement__99'] != 1]\n",
    "        newdf = newdf[newdf['client_gender__'] != 1]\n",
    "        newdf = newdf[newdf['agency_region__12'] != 1]\n",
    "        \n",
    "        del newdf['merchant_departement__99']\n",
    "        del newdf['client_gender__']\n",
    "        del newdf['agency_region__12']\n",
    "        \n",
    "        print (newdf.columns)\n",
    "\n",
    "        newdf.to_csv (r'../data_output/export_dataframe_{}v5.csv'.format(i), index = None, header=False)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/2 ...\n",
      "Index([                                    0,\n",
      "                                           0,\n",
      "                          'client_gender__F',\n",
      "                          'client_gender__M',\n",
      "                            'debit_type__TC',\n",
      "                            'debit_type__TD',\n",
      "                          'agency_region__0',\n",
      "                          'agency_region__1',\n",
      "                          'agency_region__2',\n",
      "                          'agency_region__3',\n",
      "                          'agency_region__4',\n",
      "                          'agency_region__5',\n",
      "                          'agency_region__6',\n",
      "                          'agency_region__7',\n",
      "                          'agency_region__8',\n",
      "                          'agency_region__9',\n",
      "                         'agency_region__10',\n",
      "                         'agency_region__11',\n",
      "            'merchant_departement__AMAZONAS',\n",
      "              'merchant_departement__ANCASH',\n",
      "            'merchant_departement__APURIMAC',\n",
      "            'merchant_departement__AREQUIPA',\n",
      "            'merchant_departement__AYACUCHO',\n",
      "           'merchant_departement__CAJAMARCA',\n",
      "              'merchant_departement__CALLAO',\n",
      "               'merchant_departement__CUSCO',\n",
      "        'merchant_departement__HUANCAVELICA',\n",
      "             'merchant_departement__HUÁNUCO',\n",
      "                 'merchant_departement__ICA',\n",
      "               'merchant_departement__JUNIN',\n",
      "         'merchant_departement__LA LIBERTAD',\n",
      "          'merchant_departement__LAMBAYEQUE',\n",
      "                'merchant_departement__LIMA',\n",
      "              'merchant_departement__LORETO',\n",
      "       'merchant_departement__MADRE DE DIOS',\n",
      "            'merchant_departement__MOQUEGUA',\n",
      "               'merchant_departement__PASCO',\n",
      "               'merchant_departement__PIURA',\n",
      "                'merchant_departement__PUNO',\n",
      "          'merchant_departement__SAN MARTIN',\n",
      "               'merchant_departement__TACNA',\n",
      "              'merchant_departement__TUMBES',\n",
      "             'merchant_departement__UCAYALI',\n",
      "                              'social_class'],\n",
      "      dtype='object')\n",
      "Processing 1/2 ...\n",
      "Index([                                    0,\n",
      "                                           0,\n",
      "                          'client_gender__F',\n",
      "                          'client_gender__M',\n",
      "                            'debit_type__TC',\n",
      "                            'debit_type__TD',\n",
      "                          'agency_region__0',\n",
      "                          'agency_region__1',\n",
      "                          'agency_region__2',\n",
      "                          'agency_region__3',\n",
      "                          'agency_region__4',\n",
      "                          'agency_region__5',\n",
      "                          'agency_region__6',\n",
      "                          'agency_region__7',\n",
      "                          'agency_region__8',\n",
      "                          'agency_region__9',\n",
      "                         'agency_region__10',\n",
      "                         'agency_region__11',\n",
      "            'merchant_departement__AMAZONAS',\n",
      "              'merchant_departement__ANCASH',\n",
      "            'merchant_departement__APURIMAC',\n",
      "            'merchant_departement__AREQUIPA',\n",
      "            'merchant_departement__AYACUCHO',\n",
      "           'merchant_departement__CAJAMARCA',\n",
      "              'merchant_departement__CALLAO',\n",
      "               'merchant_departement__CUSCO',\n",
      "        'merchant_departement__HUANCAVELICA',\n",
      "             'merchant_departement__HUÁNUCO',\n",
      "                 'merchant_departement__ICA',\n",
      "               'merchant_departement__JUNIN',\n",
      "         'merchant_departement__LA LIBERTAD',\n",
      "          'merchant_departement__LAMBAYEQUE',\n",
      "                'merchant_departement__LIMA',\n",
      "              'merchant_departement__LORETO',\n",
      "       'merchant_departement__MADRE DE DIOS',\n",
      "            'merchant_departement__MOQUEGUA',\n",
      "               'merchant_departement__PASCO',\n",
      "               'merchant_departement__PIURA',\n",
      "                'merchant_departement__PUNO',\n",
      "          'merchant_departement__SAN MARTIN',\n",
      "               'merchant_departement__TACNA',\n",
      "              'merchant_departement__TUMBES',\n",
      "             'merchant_departement__UCAYALI',\n",
      "                              'social_class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "extract_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlineHT",
   "language": "python",
   "name": "onlineht"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
